{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from DeepLearning.PPO import MaskablePPO\n",
    "from DeepLearning.Thesis.Environments.DummyEnv import DummyEnv\n",
    "from DeepLearning.GetActionMask import getActionMask\n",
    "from DeepLearning.Thesis.Observations.get_observation import getObservation\n",
    "import os\n",
    "\n",
    "# os.environ[\"UPDATE_MODELS_DIST\"] = \"False\"\n",
    "# os.environ[\"MODEL_1_NAME\"] = \"\"\n",
    "# os.environ[\"MODEL_2_NAME\"] = \"\"\n",
    "# os.environ[\"MODEL_3_NAME\"] = \"\"\n",
    "# os.environ[\"TURN_LIMIT\"] = \"50\"\n",
    "\n",
    "env = DummyEnv()\n",
    "actionMask = getActionMask\n",
    "observation = getObservation\n",
    "\n",
    "netArchDict = dict(pi=[128, 128, 128], vf=[128, 128, 128])\n",
    "gamma = 0.99\n",
    "n_steps = 4096\n",
    "\n",
    "saveName = \"TurnLimitMultiModelCity\"\n",
    "savePath = f\"DeepLearning/Thesis/6.DenseRewards/Models/{saveName}\"\n",
    "\n",
    "model = MaskablePPO(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=netArchDict), gamma=gamma, n_steps=n_steps, getActionMask=actionMask, getObservation=observation, savePath=savePath, tensorboard_log=\"./tensorboard_logs_thesis/\")\n",
    "model.save(\"/DeepLearning/Thesis/7.Trading/Models/SelfPlayStarter.zip\")\n",
    "# model = MaskablePPO.load(\"DeepLearning/Thesis/Setup/Models/SetupRandomFirstSettlement/model_154k.zip\", env=env)\n",
    "# model.savePath = savePath\n",
    "# model.learn(total_timesteps=20_000_000, tb_log_name=saveName, reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentName             WinRate    MarginError    numTurns    victoryPoints    numRoadsBuilt    devCardsBought  usedDevCards                 settlementsBuilt    citiesBuilt    devCardVP    largestArmy    longestRoad  resourcesReceived            totalResourcesReceivedPerTurn    totalResourcesDiscarded    totalResourcesStolen  resourcesFromDevCard         totalResourcesFromDevCard  resourcesFromBankTrade     finalResourceProduction              finalTradeRates                      setupResourceProduction                totalSetupResourceProduction  setupTradeRates                        setupResourceDiversity    turnsForFirstSettlement    noSettlementsBuilt    turnsForFirstCity    noCitysBuilt    numRoadsFor1stSettlement    totalResourcesFromBankTrade    goodSettlementBankTrades    badSettlementBankTrades    goodCityBankTrades    badCityBankTrades    goodRoadBankTrades    badRoadBankTrades    goodDevCardBankTrades    badDevCardBankTrades    neutralBankTrades    acceptedTrades    rejectedTrades    goodSettlementAcceptedTrades    badSettlementAcceptedTrades    goodCityAcceptedTrades    badCityAcceptedTrades    goodRoadAcceptedTrades    badRoadAcceptedTrades    goodDevCardAcceptedTrades    badDevCardAcceptedTrades    neutralAcceptedTrades    totalPlayerTrades    acceptedPlayerTrades    goodSettlementPlayerTrades    badSettlementPlayerTrades    goodCityPlayerTrades    badCityPlayerTrades    goodRoadPlayerTrades    badRoadPlayerTrades    goodDevCardPlayerTrades    badDevCardPlayerTrades    neutralPlayerTrades\n",
      "------------------  ---------  -------------  ----------  ---------------  ---------------  ----------------  -------------------------  ------------------  -------------  -----------  -------------  -------------  -------------------------  -------------------------------  -------------------------  ----------------------  -------------------------  ---------------------------  -------------------------  -----------------------------------  -----------------------------------  -----------------------------------  ------------------------------  -----------------------------------  ------------------------  -------------------------  --------------------  -------------------  --------------  --------------------------  -----------------------------  --------------------------  -------------------------  --------------------  -------------------  --------------------  -------------------  -----------------------  ----------------------  -------------------  ----------------  ----------------  ------------------------------  -----------------------------  ------------------------  -----------------------  ------------------------  -----------------------  ---------------------------  --------------------------  -----------------------  -------------------  ----------------------  ----------------------------  ---------------------------  ----------------------  ---------------------  ----------------------  ---------------------  -------------------------  ------------------------  ---------------------\n",
      "Player0                     0              0          -1                0                2                 0  [0.0, 0.0, 0.0, 0.0, 0.0]                   0              0            0              0              0  [0.0, 0.0, 0.0, 0.0, 0.0]                               -0                          0                       0  [0.0, 0.0, 0.0, 0.0, 0.0]                            0  [0.0, 0.0, 0.0, 0.0, 0.0]  [4.054, 2.378, 4.09, 3.737, 5.107]   [3.888, 3.911, 3.892, 3.885, 3.896]  [4.054, 2.378, 4.09, 3.737, 5.107]                           19.366  [3.888, 3.911, 3.892, 3.885, 3.896]                     3.576                          0                     1                    0               1                           0                              0                           0                          0                     0                    0                     0                    0                        0                       0                    0                 0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "Player0LossesStats         -1             -1          -1                0                2                 0  [0.0, 0.0, 0.0, 0.0, 0.0]                   0              0            0              0              0  [0.0, 0.0, 0.0, 0.0, 0.0]                               -0                          0                       0  [0.0, 0.0, 0.0, 0.0, 0.0]                            0  [0.0, 0.0, 0.0, 0.0, 0.0]  [4.054, 2.378, 4.09, 3.737, 5.107]   [3.888, 3.911, 3.892, 3.885, 3.896]  [4.054, 2.378, 4.09, 3.737, 5.107]                           19.366  [3.888, 3.911, 3.892, 3.885, 3.896]                     3.576                          0                     1                    0               1                           0                              0                           0                          0                     0                    0                     0                    0                        0                       0                    0                 0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "Player1                     0              0          -1                0                2                 0  [0.0, 0.0, 0.0, 0.0, 0.0]                   0              0            0              0              0  [0.0, 0.0, 0.0, 0.0, 0.0]                               -0                          0                       0  [0.0, 0.0, 0.0, 0.0, 0.0]                            0  [0.0, 0.0, 0.0, 0.0, 0.0]  [1.977, 2.1, 2.733, 2.78, 2.619]     [3.568, 3.555, 3.559, 3.555, 3.552]  [1.977, 2.1, 2.733, 2.78, 2.619]                             12.209  [3.568, 3.555, 3.559, 3.555, 3.552]                     2.918                          0                     1                    0               1                           0                              0                           0                          0                     0                    0                     0                    0                        0                       0                    0                 0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "Player2                     0              0          -1                0                2                 0  [0.0, 0.0, 0.0, 0.0, 0.0]                   0              0            0              0              0  [0.0, 0.0, 0.0, 0.0, 0.0]                               -0                          0                       0  [0.0, 0.0, 0.0, 0.0, 0.0]                            0  [0.0, 0.0, 0.0, 0.0, 0.0]  [1.922, 2.147, 2.729, 2.953, 2.765]  [3.549, 3.576, 3.564, 3.577, 3.609]  [1.922, 2.147, 2.729, 2.953, 2.765]                          12.516  [3.549, 3.576, 3.564, 3.577, 3.609]                     2.907                          0                     1                    0               1                           0                              0                           0                          0                     0                    0                     0                    0                        0                       0                    0                 0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "Player3                     1              0          -1                0                2                 0  [0.0, 0.0, 0.0, 0.0, 0.0]                   0              0            0              0              0  [0.0, 0.0, 0.0, 0.0, 0.0]                               -0                          0                       0  [0.0, 0.0, 0.0, 0.0, 0.0]                            0  [0.0, 0.0, 0.0, 0.0, 0.0]  [2.017, 2.154, 2.908, 2.73, 2.624]   [3.56, 3.54, 3.552, 3.558, 3.568]    [2.017, 2.154, 2.908, 2.73, 2.624]                           12.433  [3.56, 3.54, 3.552, 3.558, 3.568]                       2.897                          0                     1                    0               1                           0                              0                           0                          0                     0                    0                     0                    0                        0                       0                    0                 0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "\n",
      "Num turns: 0\n",
      "\n",
      "\n",
      "Winnings:  [0, 0, 0, 1000]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running Agent simulations\n",
    "\"\"\"\n",
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from Agents.AgentUCT import AgentUCT\n",
    "from Agents.AgentModel import AgentMultiModel, AgentModel\n",
    "from Game.CatanGame import *\n",
    "from CatanSimulator import CreateGame\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from Game.CatanPlayer import PlayerStatsTracker\n",
    "from tabulate import tabulate\n",
    "from DeepLearning.Stats import headers\n",
    "import dill as pickle\n",
    "from CatanData.GameStateViewer import SaveGameStateImage, DisplayImage\n",
    "import math\n",
    "import time\n",
    "\n",
    "winner = [0,0,0,0]\n",
    "player0Stats = PlayerStatsTracker()\n",
    "Player0LosingStats = PlayerStatsTracker()\n",
    "player1Stats = PlayerStatsTracker()\n",
    "player2Stats = PlayerStatsTracker()\n",
    "player3Stats = PlayerStatsTracker()\n",
    "\n",
    "setupModel = MaskablePPO.load(\"DeepLearning/Thesis/Setup/Models/SetupRandomFirstSettlement/model_335347_0.zip\")\n",
    "\n",
    "# testModel0 = MaskablePPO.load(\"DeepLearning/Thesis/5.Opponents/Models/Distribution/model_14966784.zip\")\n",
    "# testModel1 = MaskablePPO.load(\"DeepLearning/Thesis/4.Baseline/Models/Reward_win_10M.zip\")\n",
    "# testModel2 = MaskablePPO.load(\"DeepLearning/Thesis/Rewards/Models/Reward_win/Reward_win_10M.zip\")\n",
    "# testModel3 = MaskablePPO.load(\"DeepLearning/Thesis/Opponents/Models/VsModel/model_1536000.zip\")\n",
    "\n",
    "players = [ AgentMultiModel(\"P0\", 0, recordStats=True, playerTrading=False, setupModel=setupModel, fullSetup=True),\n",
    "            # AgentUCT(\"P1\", 1, recordStats=True, simulationCount=100),\n",
    "            # AgentModel(\"P1\", 1, recordStats=True, playerTrading=False, model=testModel1),\n",
    "            # AgentModel(\"P2\", 2, recordStats=True, playerTrading=False, model=testModel2),\n",
    "            # AgentModel(\"P3\", 3, recordStats=True, playerTrading=False, model=testModel3),\n",
    "            AgentRandom2(\"P1\", 1, recordStats=True, playerTrading=False),\n",
    "            AgentRandom2(\"P2\", 2, recordStats=True, playerTrading=False),\n",
    "            AgentRandom2(\"P3\", 3, recordStats=True, playerTrading=False),\n",
    "            ]\n",
    "\n",
    "\n",
    "COLLECT_STATS = True\n",
    "for episode in range(1000):\n",
    "    game = CreateGame(players)\n",
    "    game = pickle.loads(pickle.dumps(game, -1))\n",
    "    numTurns = 0\n",
    "    while True:\n",
    "        currPlayer = game.gameState.players[game.gameState.currPlayer]\n",
    "\n",
    "        agentAction = currPlayer.DoMove(game)\n",
    "        agentAction.ApplyAction(game.gameState)\n",
    "\n",
    "        if currPlayer.seatNumber == 0 and agentAction.type == 'EndTurn':\n",
    "            # DisplayImage(game.gameState, agentAction)\n",
    "            # time.sleep(1)\n",
    "            numTurns += 1\n",
    "\n",
    "        if game.gameState.currState == \"OVER\" or game.gameState.currState == \"PLAY\":\n",
    "            break\n",
    "    \n",
    "    # print(\"Winner: \", game.gameState.winner)\n",
    "    winner[game.gameState.winner] += 1\n",
    "    lost = game.gameState.winner != 0\n",
    "\n",
    "    # print(winner)\n",
    "\n",
    "    # Stats\n",
    "    if COLLECT_STATS:\n",
    "        game.gameState.players[0].generatePlayerStats()\n",
    "        game.gameState.players[1].generatePlayerStats()\n",
    "        game.gameState.players[2].generatePlayerStats()\n",
    "        game.gameState.players[3].generatePlayerStats()\n",
    "\n",
    "        player0Stats += game.gameState.players[0].stats\n",
    "        player1Stats += game.gameState.players[1].stats\n",
    "        player2Stats += game.gameState.players[2].stats\n",
    "        player3Stats += game.gameState.players[3].stats\n",
    "        if lost:\n",
    "            Player0LosingStats += game.gameState.players[0].stats\n",
    "\n",
    "# Collect stats\n",
    "if COLLECT_STATS:\n",
    "    player0Stats.getAverages()\n",
    "    Player0LosingStats.getAverages()\n",
    "    player1Stats.getAverages()\n",
    "    player2Stats.getAverages()\n",
    "    player3Stats.getAverages()\n",
    "    player0Data = player0Stats.getList()\n",
    "    player0LosingData = Player0LosingStats.getList()\n",
    "    player1Data = player1Stats.getList()\n",
    "    player2Data = player2Stats.getList()\n",
    "    player3Data = player3Stats.getList()\n",
    "\n",
    "    p_hat0 = winner[0] / sum(winner)\n",
    "    p_hat1 = winner[1] / sum(winner)\n",
    "    p_hat2 = winner[0] / sum(winner)\n",
    "    p_hat3 = winner[1] / sum(winner)\n",
    "    margin_error0 = round(100*(1.96 * math.sqrt((p_hat0 * (1 - p_hat0)) / sum(winner))), 2)\n",
    "    margin_error1 = round(100*(1.96 * math.sqrt((p_hat1 * (1 - p_hat1)) / sum(winner))), 2)\n",
    "    margin_error2 = round(100*(1.96 * math.sqrt((p_hat0 * (1 - p_hat0)) / sum(winner))), 2)\n",
    "    margin_error3 = round(100*(1.96 * math.sqrt((p_hat1 * (1 - p_hat1)) / sum(winner))), 2)\n",
    "    player0Data.insert(0, margin_error0)\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, margin_error1)\n",
    "    player2Data.insert(0, margin_error2)\n",
    "    player3Data.insert(0, margin_error3)\n",
    "    player0Data.insert(0, winner[0]/sum(winner))\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, winner[1]/sum(winner))\n",
    "    player2Data.insert(0, winner[2]/sum(winner))\n",
    "    player3Data.insert(0, winner[3]/sum(winner))\n",
    "    player0Data.insert(0, \"Player0\")\n",
    "    player0LosingData.insert(0, \"Player0LossesStats\")\n",
    "    player1Data.insert(0, \"Player1\")\n",
    "    player2Data.insert(0, \"Player2\")\n",
    "    player3Data.insert(0, \"Player3\")\n",
    "\n",
    "    table = tabulate([player0Data, player0LosingData, player1Data, player2Data, player3Data], headers=headers, tablefmt='simple')\n",
    "    print(table)\n",
    "\n",
    "print(f\"\\nNum turns: {numTurns}\")\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save to csv\n",
    "fileName = f'vsBaseline_v_Baseline.csv'\n",
    "df = pd.DataFrame([player0Data, player0LosingData, player1Data], columns=headers)\n",
    "df.to_csv(f'DeepLearning/Thesis/5.Opponents/Data/{fileName}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
