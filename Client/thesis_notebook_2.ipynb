{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./tensorboard_logs_thesis/Reward_finalvp_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldrummond/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96.8     |\n",
      "|    ep_rew_mean     | 5.64     |\n",
      "| time/              |          |\n",
      "|    fps             | 890      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.1        |\n",
      "|    ep_rew_mean          | 6.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020831073 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0904     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldrummond/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:283: UserWarning: Path 'DeepLearning/Thesis/Rewards/Models/Reward_finalvp' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 104         |\n",
      "|    ep_rew_mean          | 6.42        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029532395 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0379     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.5        |\n",
      "|    ep_rew_mean          | 6.11        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024168672 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0183     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    value_loss           | 0.0809      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.8        |\n",
      "|    ep_rew_mean          | 5.54        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 579         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032902557 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.063       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 78.7        |\n",
      "|    ep_rew_mean          | 5.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031522162 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0486     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0436     |\n",
      "|    value_loss           | 0.0699      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.6       |\n",
      "|    ep_rew_mean          | 5.16       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 544        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 52         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03566441 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | 0.85       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0888    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0518    |\n",
      "|    value_loss           | 0.0516     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 80.5       |\n",
      "|    ep_rew_mean          | 5.49       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 526        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03462631 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.74      |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0835    |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0552    |\n",
      "|    value_loss           | 0.0518     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.3        |\n",
      "|    ep_rew_mean          | 5.88        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034199253 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0702     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0457     |\n",
      "|    value_loss           | 0.0413      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 77.7        |\n",
      "|    ep_rew_mean          | 6.07        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042317405 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0887     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0498     |\n",
      "|    value_loss           | 0.0415      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.6        |\n",
      "|    ep_rew_mean          | 6.23        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037262093 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0784     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0529     |\n",
      "|    value_loss           | 0.0462      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 82         |\n",
      "|    ep_rew_mean          | 6.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03859932 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | 0.786      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0605    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0483    |\n",
      "|    value_loss           | 0.0516     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 84.5        |\n",
      "|    ep_rew_mean          | 6.84        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037194967 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0517     |\n",
      "|    value_loss           | 0.0591      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.1        |\n",
      "|    ep_rew_mean          | 7.51        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045431152 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.093      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0523     |\n",
      "|    value_loss           | 0.0462      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 89.6       |\n",
      "|    ep_rew_mean          | 7.74       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 487        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04422742 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0636    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0501    |\n",
      "|    value_loss           | 0.0528     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.7        |\n",
      "|    ep_rew_mean          | 7.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 481         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046608604 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0993     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0522     |\n",
      "|    value_loss           | 0.04        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 85.8      |\n",
      "|    ep_rew_mean          | 8.06      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 480       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 145       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0484954 |\n",
      "|    clip_fraction        | 0.35      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.37     |\n",
      "|    explained_variance   | 0.83      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0992   |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0506   |\n",
      "|    value_loss           | 0.0518    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 86.7        |\n",
      "|    ep_rew_mean          | 8.33        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045657106 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0625     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0513     |\n",
      "|    value_loss           | 0.0492      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.6        |\n",
      "|    ep_rew_mean          | 8.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050696455 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0697     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0544     |\n",
      "|    value_loss           | 0.0428      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 88.8      |\n",
      "|    ep_rew_mean          | 8.68      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 469       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 174       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0447468 |\n",
      "|    clip_fraction        | 0.332     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.31     |\n",
      "|    explained_variance   | 0.794     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0771   |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.0465   |\n",
      "|    value_loss           | 0.0408    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.9        |\n",
      "|    ep_rew_mean          | 8.72        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048321083 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.056      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0532     |\n",
      "|    value_loss           | 0.0442      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 77.9       |\n",
      "|    ep_rew_mean          | 8.42       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 465        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 193        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04570035 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.848      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0577    |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0508    |\n",
      "|    value_loss           | 0.0431     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.5       |\n",
      "|    ep_rew_mean          | 8.47       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 465        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05279284 |\n",
      "|    clip_fraction        | 0.361      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.847      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0833    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0521    |\n",
      "|    value_loss           | 0.0486     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.2        |\n",
      "|    ep_rew_mean          | 8.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047452938 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0788     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0535     |\n",
      "|    value_loss           | 0.0407      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 80.2       |\n",
      "|    ep_rew_mean          | 9.13       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 464        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 220        |\n",
      "|    total_timesteps      | 102400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05739265 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.813      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0698    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0561    |\n",
      "|    value_loss           | 0.037      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.6        |\n",
      "|    ep_rew_mean          | 9.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047843285 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0762     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0461     |\n",
      "|    value_loss           | 0.0336      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.5        |\n",
      "|    ep_rew_mean          | 9.18        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053127233 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0859     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0472     |\n",
      "|    value_loss           | 0.0399      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 85.2       |\n",
      "|    ep_rew_mean          | 9.14       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 465        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 246        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05408676 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.766      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.079     |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0473    |\n",
      "|    value_loss           | 0.0404     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82          |\n",
      "|    ep_rew_mean          | 8.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050312374 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0828     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0501     |\n",
      "|    value_loss           | 0.0374      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 81.7       |\n",
      "|    ep_rew_mean          | 9.04       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 466        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 263        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06253176 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.852      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0883    |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0507    |\n",
      "|    value_loss           | 0.0308     |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from DeepLearning.PPO import MaskablePPO\n",
    "from DeepLearning.Thesis.Environments.RewardTesting import FinalvpRewardEnv\n",
    "from DeepLearning.GetActionMask import getActionMask\n",
    "from DeepLearning.Thesis.Observations.get_observation import getObservation, lowerBound, upperBound\n",
    "import os\n",
    "\n",
    "env = FinalvpRewardEnv(lowerBounds=lowerBound, upperBounds=upperBound, getObservationFunction=getObservation, getActionMaskFunction=getActionMask)\n",
    "actionMask = getActionMask\n",
    "observation = getObservation\n",
    "\n",
    "netArchDict = dict(pi=[128, 128, 128], vf=[128, 128, 128])\n",
    "gamma = 0.99\n",
    "n_steps = 4096\n",
    "\n",
    "saveName = \"Reward_finalvp\"\n",
    "savePath = f\"DeepLearning/Thesis/Rewards/Models/{saveName}\"\n",
    "\n",
    "model = MaskablePPO(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=netArchDict), gamma=gamma, n_steps=n_steps, getActionMask=actionMask, getObservation=observation, savePath=savePath, tensorboard_log=\"./tensorboard_logs_thesis/\")\n",
    "model.learn(total_timesteps=2_000_000, tb_log_name=saveName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running Agent simulations\n",
    "\"\"\"\n",
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from Agents.AgentUCT import AgentUCT\n",
    "from Agents.AgentModel import AgentMultiModel, AgentModel\n",
    "from Game.CatanGame import *\n",
    "from CatanSimulator import CreateGame\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from Game.CatanPlayer import PlayerStatsTracker\n",
    "from tabulate import tabulate\n",
    "from DeepLearning.Stats import headers\n",
    "import dill as pickle\n",
    "from CatanData.GameStateViewer import SaveGameStateImage, DisplayImage\n",
    "import math\n",
    "from DeepLearning.Environments.CatanEnv import CatanEnv, SelfPlayDistribution, CatanTradingEnv, SelfPlayDistTradingEnv\n",
    "\n",
    "from DeepLearning.Thesis.Observations.nodes_v_hexes import getNodeInHexObs, nodeInHexLowerBound, nodeInHexUpperBound\n",
    "\n",
    "winner = [0,0,0,0]\n",
    "player0Stats = PlayerStatsTracker()\n",
    "Player0LosingStats = PlayerStatsTracker()\n",
    "player1Stats = PlayerStatsTracker()\n",
    "\n",
    "\n",
    "testModel = MaskablePPO.load(\"DeepLearning/Thesis/Hyperparameters/Models/NumSteps_8192/Final.zip\")\n",
    "# testModel2 = MaskablePPO.load(\"DeepLearning/Thesis/Hyperparameters/Models/NetworkArch_128_128/Final.zip\")\n",
    "# testModel3 = MaskablePPO.load(\"DeepLearning/Thesis/Hyperparameters/Models/NetworkArch_256_256/Final.zip\")\n",
    "# testModel4 = MaskablePPO.load(\"DeepLearning/Thesis/Hyperparameters/Models/NetworkArch_512_512/Final.zip\")\n",
    "\n",
    "players = [ AgentModel(\"P0\", 0, recordStats=True, playerTrading=False, model=testModel),\n",
    "            # AgentModel(\"P1\", 1, recordStats=True, playerTrading=False, model=testModel2),\n",
    "            AgentRandom2(\"P1\", 1, recordStats=True, playerTrading=False),\n",
    "            AgentRandom2(\"P2\", 2, recordStats=True, playerTrading=False),\n",
    "            AgentRandom2(\"P3\", 3, recordStats=True, playerTrading=False),]\n",
    "\n",
    "\n",
    "COLLECT_STATS = True\n",
    "for episode in range(2000):\n",
    "    game = CreateGame(players)\n",
    "    game = pickle.loads(pickle.dumps(game, -1))\n",
    "    numTurns = 0\n",
    "    while True:\n",
    "        currPlayer = game.gameState.players[game.gameState.currPlayer]\n",
    "\n",
    "        agentAction = currPlayer.DoMove(game)\n",
    "        agentAction.ApplyAction(game.gameState)\n",
    "\n",
    "        if currPlayer.seatNumber == 0 and agentAction.type == 'EndTurn':\n",
    "        #     DisplayImage(game.gameState, agentAction)\n",
    "        #     time.sleep(1)\n",
    "            numTurns += 1\n",
    "\n",
    "        if game.gameState.currState == \"OVER\":\n",
    "            # DisplayImage(game.gameState, agentAction)\n",
    "            break\n",
    "    \n",
    "    # print(\"Winner: \", game.gameState.winner)\n",
    "    winner[game.gameState.winner] += 1\n",
    "    lost = game.gameState.winner != 0\n",
    "\n",
    "    # Stats\n",
    "    if COLLECT_STATS:\n",
    "        game.gameState.players[0].generatePlayerStats()\n",
    "        game.gameState.players[1].generatePlayerStats()\n",
    "\n",
    "        player0Stats += game.gameState.players[0].stats\n",
    "        player1Stats += game.gameState.players[1].stats\n",
    "        if lost:\n",
    "            Player0LosingStats += game.gameState.players[0].stats\n",
    "\n",
    "# Collect stats\n",
    "if COLLECT_STATS:\n",
    "    player0Stats.getAverages()\n",
    "    Player0LosingStats.getAverages()\n",
    "    player1Stats.getAverages()\n",
    "    player0Data = player0Stats.getList()\n",
    "    player0LosingData = Player0LosingStats.getList()\n",
    "    player1Data = player1Stats.getList()\n",
    "\n",
    "    p_hat0 = winner[0] / sum(winner)\n",
    "    p_hat1 = winner[1] / sum(winner)\n",
    "    margin_error0 = round(100*(1.96 * math.sqrt((p_hat0 * (1 - p_hat0)) / sum(winner))), 2)\n",
    "    margin_error1 = round(100*(1.96 * math.sqrt((p_hat1 * (1 - p_hat1)) / sum(winner))), 2)\n",
    "    player0Data.insert(0, margin_error0)\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, margin_error1)\n",
    "    player0Data.insert(0, winner[0]/sum(winner))\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, winner[1]/sum(winner))\n",
    "    player0Data.insert(0, \"Player0\")\n",
    "    player0LosingData.insert(0, \"Player0LossesStats\")\n",
    "    player1Data.insert(0, \"Player1\")\n",
    "\n",
    "    table = tabulate([player0Data, player0LosingData, player1Data], headers=headers, tablefmt='simple')\n",
    "    print(table)\n",
    "\n",
    "print(f\"\\nNum turns: {numTurns}\")\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save to csv\n",
    "fileName = f'NumSteps_8192_v_3Random.csv'\n",
    "df = pd.DataFrame([player0Data, player0LosingData, player1Data], columns=headers)\n",
    "df.to_csv(f'DeepLearning/Thesis/Hyperparameters/Data/{fileName}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
