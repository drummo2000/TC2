{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepLearning.Environments.NoSetupEnv import NoSetupDenseRewardEnv\n",
    "from DeepLearning.Environments.SetupEnv import SetupRandomWithRoadsEnv\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "#env = NoSetupDenseRewardEnv(setupModel=MaskablePPO.load('DeepLearning/Models/SetupRandom_wins_1M.zip'))\n",
    "env = SetupRandomWithRoadsEnv()\n",
    "\n",
    "model = MaskablePPO(\"MlpPolicy\", env, gamma=0.4, verbose=1, tensorboard_log=\"./tensorboard_logs/\")\n",
    "model.learn(total_timesteps=1_000_000, tb_log_name='SetupRandomRoads_wins_1M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from DeepLearning.Environments.NoSetupEnv import NoSetupDenseRewardEnv\n",
    "from DeepLearning.Environments.SetupEnv import SetupRandomWithRoadsEnv\n",
    "import os\n",
    "from Game.CatanPlayer import PlayerStatsTracker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from tabulate import tabulate\n",
    "from DeepLearning.Stats import headers\n",
    "import pandas as pd\n",
    "import random\n",
    "from Agents.AgentModel import AgentModel\n",
    "\n",
    "env = NoSetupDenseRewardEnv(setupModel=MaskablePPO.load('DeepLearning/Models/SetupRandom_wins_1M.zip'))\n",
    "# env = SetupRandomWithRoadsEnv()\n",
    "modelName = \"NoSetupDenseRewardEnv-10M\"\n",
    "\n",
    "# model.save(f\"DeepLearning/Models/{modelName}\")\n",
    "model = MaskablePPO.load(f'DeepLearning/Models/{modelName}.zip')\n",
    "\n",
    "rewardList = []\n",
    "winner = [0,0,0,0]\n",
    "\n",
    "stats = PlayerStatsTracker()\n",
    "randomStats = PlayerStatsTracker()\n",
    "\n",
    "players = [ AgentRandom2(\"P0\", 0),\n",
    "            AgentRandom2(\"P1\", 1),\n",
    "            AgentRandom2(\"P2\", 2),\n",
    "            AgentRandom2(\"P3\", 3)]\n",
    "\n",
    "for episode in range(1000):\n",
    "    done = False\n",
    "    state, info = env.reset()#players=players)\n",
    "\n",
    "    while done != True:\n",
    "        action_masks = get_action_masks(env)\n",
    "        action, _states = model.predict(state, action_masks=action_masks)\n",
    "        state, reward, done, _, info = env.step(action.item())\n",
    "        rewardList.append(reward)\n",
    "\n",
    "    winner[env.game.gameState.winner] += 1\n",
    "    \n",
    "    env.game.gameState.players[0].generatePlayerStats()\n",
    "    env.game.gameState.players[3].generatePlayerStats()\n",
    "\n",
    "    stats += env.game.gameState.players[0].stats\n",
    "    randomStats += env.game.gameState.players[3].stats\n",
    "\n",
    "# Collect stats\n",
    "opponentName = \"AgentRandom\"\n",
    "\n",
    "stats.getAverages()\n",
    "randomStats.getAverages()\n",
    "\n",
    "agentData = stats.getList()\n",
    "agentData.insert(0, winner[0]/sum(winner))\n",
    "agentData.insert(0, modelName)\n",
    "randomData = randomStats.getList()\n",
    "randomData.insert(0, winner[3]/sum(winner))\n",
    "randomData.insert(0, opponentName)\n",
    "\n",
    "table = tabulate([agentData, randomData], headers=headers, tablefmt='simple')\n",
    "print(table)\n",
    "\n",
    "# Save to CSV\n",
    "# fileName = f'{modelName}_vs_3{opponentName}.csv'\n",
    "# df = pd.DataFrame([agentData, randomData], columns=headers)\n",
    "# df.to_csv(f'DeepLearning/Data/{fileName}', index=False)\n",
    "\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from Agents.AgentModel import AgentModel\n",
    "from Game.CatanGame import *\n",
    "from CatanSimulator import CreateGame\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from DeepLearning.Environments.SetupEnv import SetupRandomEnv, SetupRandomWithRoadsEnv, SetupOnlyEnv\n",
    "from DeepLearning.Environments.NoSetupEnv import NoSetupDenseRewardEnv\n",
    "import dill as pickle\n",
    "\n",
    "\n",
    "winner = [0,0,0,0]\n",
    "\n",
    "players = [ AgentModel(\"P0\", 0, setupModel=MaskablePPO.load(\"DeepLearning/Models/SetupRandom_wins_1M.zip\"), setupEnv=SetupRandomEnv(), model=MaskablePPO.load(\"DeepLearning/Models/NoSetupDenseRewardEnv-10M.zip\"), env=NoSetupDenseRewardEnv()),\n",
    "            AgentRandom2(\"P1\", 1),\n",
    "            AgentRandom2(\"P2\", 2),\n",
    "            AgentRandom2(\"P3\", 3)]\n",
    "            # AgentModel(\"P1\", 1, setupModel=MaskablePPO.load(\"DeepLearning/Models/SetupRandom_wins_100k.zip\"), setupEnv=SetupRandomEnv(), model=MaskablePPO.load(\"DeepLearning/Models/NoSetupDenseRewardEnv-10M.zip\"), env=NoSetupDenseRewardEnv()),\n",
    "            # AgentModel(\"P2\", 2, setupModel=MaskablePPO.load(\"DeepLearning/Models/SetupRandomRoads_wins_1M.zip\"), setupEnv=SetupRandomWithRoadsEnv(), model=MaskablePPO.load(\"DeepLearning/Models/NoSetupDenseRewardEnv-10M.zip\"), env=NoSetupDenseRewardEnv()),\n",
    "            # AgentModel(\"P3\", 3, setupModel=MaskablePPO.load(\"DeepLearning/Models/SetupOnly_DotTotal_100k.zip\"), setupEnv=SetupOnlyEnv(), model=MaskablePPO.load(\"DeepLearning/Models/NoSetupDenseRewardEnv-10M.zip\"), env=NoSetupDenseRewardEnv())]\n",
    "\n",
    "for episode in range(1000):\n",
    "    inGame = CreateGame(players)\n",
    "    game = pickle.loads(pickle.dumps(inGame, -1))\n",
    "    while True:\n",
    "        currPlayer = game.gameState.players[game.gameState.currPlayer]\n",
    "\n",
    "        agentAction = currPlayer.DoMove(game)\n",
    "        agentAction.ApplyAction(game.gameState)\n",
    "\n",
    "        if game.gameState.currState == \"OVER\":\n",
    "            break\n",
    "    winner[game.gameState.winner] += 1\n",
    "\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
