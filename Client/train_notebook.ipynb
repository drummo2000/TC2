{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./tensorboard_logs/BEST_MODEL_EVER_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldrummond/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4        |\n",
      "|    ep_rew_mean     | -3.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 290      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | -2.45        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 232          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125028165 |\n",
      "|    clip_fraction        | 0.157        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.00237      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.6         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0671      |\n",
      "|    value_loss           | 59.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -2.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014009278 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0745     |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4            |\n",
      "|    ep_rew_mean          | -2.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148213245 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.000907     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.6         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0778      |\n",
      "|    value_loss           | 50.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -1.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016146867 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | -0.0192     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0782     |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015858833 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0785     |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016783195 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0814     |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0.9         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018517077 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.0108      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0819     |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -3.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019522116 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0864     |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -0.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 246         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020212023 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.0401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0837     |\n",
      "|    value_loss           | 42          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022743698 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | -0.018      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.3        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0881     |\n",
      "|    value_loss           | 41.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022495598 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0868     |\n",
      "|    value_loss           | 39          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022505753 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0844     |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020679168 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.0428      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.27        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.08       |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023940207 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0828     |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldrummond/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:283: UserWarning: Path 'DeepLearning/models/BEST_MODEL_EVER' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 1.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 135        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02495873 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.14      |\n",
      "|    explained_variance   | 0.062      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.22       |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0822    |\n",
      "|    value_loss           | 31.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025019359 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.0989      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.31        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0795     |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -1.25       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027361237 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.6         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0813     |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -2.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028669324 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.0657      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.98        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0813     |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030192312 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 0.0918      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0762     |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034241565 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0765     |\n",
      "|    value_loss           | 27.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030511338 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.0846      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.46        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0783     |\n",
      "|    value_loss           | 27.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 198         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030545402 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | 0.0931      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.43        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0761     |\n",
      "|    value_loss           | 27.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034466494 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.0913      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.39        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0755     |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -0.35       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037933126 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.45        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0738     |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | -0.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034010917 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.0555      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.59        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0723     |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 3.05      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 235       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 235       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0347782 |\n",
      "|    clip_fraction        | 0.283     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.91     |\n",
      "|    explained_variance   | 0.147     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.66      |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.0731   |\n",
      "|    value_loss           | 24.9      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.7         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035961706 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0733     |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043310773 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.0917      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.41        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0731     |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.7        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 259        |\n",
      "|    total_timesteps      | 61440      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04340682 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.8        |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0729    |\n",
      "|    value_loss           | 25.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040626157 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0753     |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051803626 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.01        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0709     |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | -0.75      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 284        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04707356 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.81      |\n",
      "|    explained_variance   | 0.0753     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.99       |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0705    |\n",
      "|    value_loss           | 23.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.55       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05107524 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | 0.209      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.12       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0718    |\n",
      "|    value_loss           | 22         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1.4         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047620654 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0736     |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 1.4        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 308        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04889064 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | 0.097      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.85       |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0723    |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 5          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 317        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05223093 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.74      |\n",
      "|    explained_variance   | 0.195      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.99       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0702    |\n",
      "|    value_loss           | 22.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 5.1         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048296243 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.0612      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.21        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0746     |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.4        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04940514 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.52       |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0704    |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 341        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05496593 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.0173     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.04       |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0724    |\n",
      "|    value_loss           | 28.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.95       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05121376 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.68      |\n",
      "|    explained_variance   | 0.0952     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.77       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0714    |\n",
      "|    value_loss           | 25.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.9        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 357        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06069947 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.67      |\n",
      "|    explained_variance   | 0.0646     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.37       |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0721    |\n",
      "|    value_loss           | 24.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.55        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054039486 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.38        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0665     |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 372         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054278754 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0742     |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053171232 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.13        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0712     |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 389        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06418635 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.63      |\n",
      "|    explained_variance   | 0.134      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.89       |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0637    |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 6.05        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062532276 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.0863      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0674     |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.75       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 404        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06812222 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.63      |\n",
      "|    explained_variance   | 0.0598     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.91       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0697    |\n",
      "|    value_loss           | 26         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 1.4       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 242       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 413       |\n",
      "|    total_timesteps      | 100352    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0567128 |\n",
      "|    clip_fraction        | 0.372     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.58     |\n",
      "|    explained_variance   | 0.105     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.77      |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -0.0557   |\n",
      "|    value_loss           | 27.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056539718 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0724     |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 1.45       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 428        |\n",
      "|    total_timesteps      | 104448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06450091 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.54       |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.071     |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 0.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 243        |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 437        |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07370171 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | 0.108      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.76       |\n",
      "|    n_updates            | 510        |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    value_loss           | 25.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 447        |\n",
      "|    total_timesteps      | 108544     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06534287 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.09       |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0608    |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 0.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 54         |\n",
      "|    time_elapsed         | 456        |\n",
      "|    total_timesteps      | 110592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07208547 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.99       |\n",
      "|    n_updates            | 530        |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.4        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 465        |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06057796 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.53      |\n",
      "|    explained_variance   | 0.218      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.74       |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0645    |\n",
      "|    value_loss           | 22.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 473        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07230277 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.43       |\n",
      "|    n_updates            | 550        |\n",
      "|    policy_gradient_loss | -0.0605    |\n",
      "|    value_loss           | 24.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 4.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060965493 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.1         |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0631     |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 1.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 242        |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 490        |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07471337 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | 0.126      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.21       |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.062     |\n",
      "|    value_loss           | 23.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 4.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 499        |\n",
      "|    total_timesteps      | 120832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06518522 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.57       |\n",
      "|    n_updates            | 580        |\n",
      "|    policy_gradient_loss | -0.0631    |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.75        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059181117 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0677     |\n",
      "|    value_loss           | 25.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 4.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 517        |\n",
      "|    total_timesteps      | 124928     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08229441 |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.44      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.17       |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.0592    |\n",
      "|    value_loss           | 22.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.55       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 525        |\n",
      "|    total_timesteps      | 126976     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07998864 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | 0.225      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.23       |\n",
      "|    n_updates            | 610        |\n",
      "|    policy_gradient_loss | -0.0642    |\n",
      "|    value_loss           | 22.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.087842256 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.87        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0479     |\n",
      "|    value_loss           | 24.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 1.75       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 543        |\n",
      "|    total_timesteps      | 131072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08937198 |\n",
      "|    clip_fraction        | 0.397      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.82       |\n",
      "|    n_updates            | 630        |\n",
      "|    policy_gradient_loss | -0.0599    |\n",
      "|    value_loss           | 21.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 4.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 241        |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 551        |\n",
      "|    total_timesteps      | 133120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07175661 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0.223      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.19       |\n",
      "|    n_updates            | 640        |\n",
      "|    policy_gradient_loss | -0.0628    |\n",
      "|    value_loss           | 23.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 66         |\n",
      "|    time_elapsed         | 562        |\n",
      "|    total_timesteps      | 135168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07537444 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.79       |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.0616    |\n",
      "|    value_loss           | 23.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.8         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.073355556 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.19        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0646     |\n",
      "|    value_loss           | 24.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 5.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 580        |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07304054 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.04       |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.0671    |\n",
      "|    value_loss           | 24.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.6        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 590        |\n",
      "|    total_timesteps      | 141312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08628887 |\n",
      "|    clip_fraction        | 0.382      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.43       |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0674    |\n",
      "|    value_loss           | 25.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.7        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 600        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07755581 |\n",
      "|    clip_fraction        | 0.405      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.36       |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0664    |\n",
      "|    value_loss           | 25.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.65       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 238        |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 610        |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11182995 |\n",
      "|    clip_fraction        | 0.405      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.0863     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.37       |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.058     |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 72         |\n",
      "|    time_elapsed         | 620        |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10429066 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.117      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.58       |\n",
      "|    n_updates            | 710        |\n",
      "|    policy_gradient_loss | -0.0679    |\n",
      "|    value_loss           | 25.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 4.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 73         |\n",
      "|    time_elapsed         | 629        |\n",
      "|    total_timesteps      | 149504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08818427 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.187      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.42       |\n",
      "|    n_updates            | 720        |\n",
      "|    policy_gradient_loss | -0.0679    |\n",
      "|    value_loss           | 21.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.1        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 638        |\n",
      "|    total_timesteps      | 151552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09113412 |\n",
      "|    clip_fraction        | 0.422      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.1        |\n",
      "|    n_updates            | 730        |\n",
      "|    policy_gradient_loss | -0.0565    |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.7        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 75         |\n",
      "|    time_elapsed         | 647        |\n",
      "|    total_timesteps      | 153600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08157803 |\n",
      "|    clip_fraction        | 0.397      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.165      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.42       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.0595    |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4         |\n",
      "|    ep_rew_mean          | 3.65      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 237       |\n",
      "|    iterations           | 76        |\n",
      "|    time_elapsed         | 655       |\n",
      "|    total_timesteps      | 155648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0816274 |\n",
      "|    clip_fraction        | 0.365     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.26     |\n",
      "|    explained_variance   | 0.102     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.55      |\n",
      "|    n_updates            | 750       |\n",
      "|    policy_gradient_loss | -0.0683   |\n",
      "|    value_loss           | 27.8      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 664        |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09223213 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.0389     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.73       |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0644    |\n",
      "|    value_loss           | 27.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 6.2        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 673        |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07772253 |\n",
      "|    clip_fraction        | 0.364      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.238      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.51       |\n",
      "|    n_updates            | 770        |\n",
      "|    policy_gradient_loss | -0.0652    |\n",
      "|    value_loss           | 24.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 5.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 682        |\n",
      "|    total_timesteps      | 161792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09067149 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.188      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6          |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.0635    |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 6.4        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 690        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07933958 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.191      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.67       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.0647    |\n",
      "|    value_loss           | 24.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 4.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.106858924 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0531     |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 1.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 707         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.104604125 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.81        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0551     |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.102667056 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.84        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0581     |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.35       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 84         |\n",
      "|    time_elapsed         | 724        |\n",
      "|    total_timesteps      | 172032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10714359 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.135      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.42       |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.0556    |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 4.3        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 732        |\n",
      "|    total_timesteps      | 174080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09702547 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.267      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.66       |\n",
      "|    n_updates            | 840        |\n",
      "|    policy_gradient_loss | -0.0568    |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 4           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.105078876 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.123       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0553     |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 4.2         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.110740006 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.72        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0537     |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 759        |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12731615 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.215      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.06       |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.0567    |\n",
      "|    value_loss           | 22.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 3.5         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.120392956 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.993      |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0501     |\n",
      "|    value_loss           | 23.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 776         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124023825 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.33        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0485     |\n",
      "|    value_loss           | 23          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 91         |\n",
      "|    time_elapsed         | 784        |\n",
      "|    total_timesteps      | 186368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09392495 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.984     |\n",
      "|    explained_variance   | 0.236      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.23       |\n",
      "|    n_updates            | 900        |\n",
      "|    policy_gradient_loss | -0.0493    |\n",
      "|    value_loss           | 24.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4           |\n",
      "|    ep_rew_mean          | 2.45        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 237         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 793         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124539346 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.64        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0515     |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 2.85       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 802        |\n",
      "|    total_timesteps      | 190464     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10603613 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.97      |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.54       |\n",
      "|    n_updates            | 920        |\n",
      "|    policy_gradient_loss | -0.0462    |\n",
      "|    value_loss           | 24.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4          |\n",
      "|    ep_rew_mean          | 3.15       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 237        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 811        |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11474816 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.925     |\n",
      "|    explained_variance   | 0.274      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.48       |\n",
      "|    n_updates            | 930        |\n",
      "|    policy_gradient_loss | -0.051     |\n",
      "|    value_loss           | 21.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m netArchDict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(pi\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m], vf\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m])\n\u001b[1;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m MaskablePPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, changingRewardEnv, policy_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(net_arch\u001b[38;5;241m=\u001b[39mnetArchDict), gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, getActionMask\u001b[38;5;241m=\u001b[39mgetActionMask, getObservation\u001b[38;5;241m=\u001b[39mgetObservationSimplified, info\u001b[38;5;241m=\u001b[39minfo, saveName\u001b[38;5;241m=\u001b[39mname, tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tensorboard_logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# model.set_env(firstSettlementEnv)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# model.saveName = name + \"-Part2\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# model.learn(total_timesteps=2_000_000, tb_log_name=f\"{name}-Part2\")\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# model.save(f\"DeepLearning/Models/{name}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/DeepLearning/PPO.py:545\u001b[0m, in \u001b[0;36mMaskablePPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[1;32m    542\u001b[0m bestAvgReward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 545\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_masking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/DeepLearning/PPO.py:321\u001b[0m, in \u001b[0;36mMaskablePPO.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps, use_masking)\u001b[0m\n\u001b[1;32m    318\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy(obs_tensor, action_masks\u001b[38;5;241m=\u001b[39maction_masks)\n\u001b[1;32m    320\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m--> 321\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:70\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m---> 70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/stable_baselines3/common/monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/DeepLearning/Environments/CatanEnv.py:147\u001b[0m, in \u001b[0;36mChangingRewardEnv.reset\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWIN_REWARDS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwinReward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChangingRewardEnv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/DeepLearning/Environments/CatanEnv.py:47\u001b[0m, in \u001b[0;36mCatanEnv.reset\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03mSetup new game, cycle through actions till agents turn, return current state and set action mask\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m inGame \u001b[38;5;241m=\u001b[39m CreateGame([   AgentRandom2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m     44\u001b[0m                         AgentRandom2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     45\u001b[0m                         AgentRandom2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     46\u001b[0m                         AgentRandom2(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m3\u001b[39m)], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustomBoard)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mloads(\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43minGame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mgameState\u001b[38;5;241m.\u001b[39mplayers\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame\u001b[38;5;241m.\u001b[39mgameState\u001b[38;5;241m.\u001b[39mplayers[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:280\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03mPickle an object to a string.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03mDefault values for keyword arguments can be set in :mod:`dill.settings`.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m file \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m--> 280\u001b[0m \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, strictio)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:252\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[1;32m    250\u001b[0m _kwds \u001b[38;5;241m=\u001b[39m kwds\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    251\u001b[0m _kwds\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(byref\u001b[38;5;241m=\u001b[39mbyref, fmode\u001b[38;5;241m=\u001b[39mfmode, recurse\u001b[38;5;241m=\u001b[39mrecurse))\n\u001b[0;32m--> 252\u001b[0m \u001b[43mPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:420\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace_setup(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 420\u001b[0m     \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:1217\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dill(pickler, child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m pickler\u001b[38;5;241m.\u001b[39m_session:\n\u001b[1;32m   1215\u001b[0m         \u001b[38;5;66;03m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m         pickler\u001b[38;5;241m.\u001b[39m_first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1218\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace(pickler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# D2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:1217\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dill(pickler, child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m pickler\u001b[38;5;241m.\u001b[39m_session:\n\u001b[1;32m   1215\u001b[0m         \u001b[38;5;66;03m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m         pickler\u001b[38;5;241m.\u001b[39m_first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1218\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace(pickler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# D2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:998\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m    997\u001b[0m         save(k)\n\u001b[0;32m--> 998\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m     write(SETITEMS)\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:1217\u001b[0m, in \u001b[0;36msave_module_dict\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_dill(pickler, child\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m pickler\u001b[38;5;241m.\u001b[39m_session:\n\u001b[1;32m   1215\u001b[0m         \u001b[38;5;66;03m# we only care about session the first pass thru\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m         pickler\u001b[38;5;241m.\u001b[39m_first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m     \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1218\u001b[0m     logger\u001b[38;5;241m.\u001b[39mtrace(pickler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# D2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:972\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 972\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m write(MARK)\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[0;32m--> 997\u001b[0m     \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     save(v)\n\u001b[1;32m    999\u001b[0m write(SETITEMS)\n",
      "File \u001b[0;32m~/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/dill/_dill.py:414\u001b[0m, in \u001b[0;36mPickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    412\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt pickle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: attribute lookup builtins.generator failed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m GeneratorType\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m--> 414\u001b[0m \u001b[43mStockPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_persistent_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7/Frameworks/Python.framework/Versions/3.11/lib/python3.11/pickle.py:759\u001b[0m, in \u001b[0;36m_Pickler.save_long\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0xff\u001b[39m:\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(BININT1 \u001b[38;5;241m+\u001b[39m pack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<B\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj))\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0xffff\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from DeepLearning.Environments.NoSetupEnv import NoSetupDenseRewardEnv\n",
    "from DeepLearning.Environments.SetupEnv import SetupRandomWithRoadsEnv, SetupOnlyEnv\n",
    "from DeepLearning.Environments.CatanEnv import CatanEnv, ChangingRewardEnv\n",
    "from DeepLearning.Environments.SelfPlayEnv import SelfPlayEnv, SelfPlaySetupDotTotalEnv\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from DeepLearning.GetActionMask import getActionMask\n",
    "from DeepLearning.GetObservation import getObservation, getObservationSimplified, lowerBoundsSimplified, upperBoundsSimplified\n",
    "from Agents.AgentModel import AgentMultiModel\n",
    "import os\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "os.environ[\"UPDATE_MODELS\"] = \"False\"\n",
    "os.environ[\"MODEL_NAME\"] = \"None\"\n",
    "os.environ[\"VP_REWARDS\"] = \"False\"\n",
    "os.environ[\"WIN_REWARDS\"] = \"False\"\n",
    "\n",
    "changingRewardEnv = ChangingRewardEnv()\n",
    "\n",
    "info = {\n",
    "    \"env\": \"Diversity\",\n",
    "    \"Timesteps\": \"500k\",\n",
    "    \"Opponents\": \"3x(Random)\",\n",
    "    \"Rewards\": \"Diversity 5 gives 30, vpActions*2\"\n",
    "}\n",
    "name = \"BEST_MODEL_EVER\"\n",
    "\n",
    "netArchDict = dict(pi=[128, 128], vf=[128, 128])\n",
    "\n",
    "\n",
    "model = MaskablePPO(\"MlpPolicy\", changingRewardEnv, policy_kwargs=dict(net_arch=netArchDict), gamma=0.4, verbose=1, getActionMask=getActionMask, getObservation=getObservationSimplified, info=info, saveName=name, tensorboard_log=\"./tensorboard_logs/\")\n",
    "model.learn(total_timesteps=500_000, tb_log_name=f\"{name}\")\n",
    "# model.set_env(firstSettlementEnv)\n",
    "# model.saveName = name + \"-Part2\"\n",
    "# model.learn(total_timesteps=2_000_000, tb_log_name=f\"{name}-Part2\")\n",
    "# model.save(f\"DeepLearning/Models/{name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Trained model using env format, use to debug running environments \n",
    "\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "from DeepLearning.Environments.NoSetupEnv import NoSetupDenseRewardEnv, NoSetupEnv\n",
    "from DeepLearning.Environments.SetupEnv import SetupRandomWithRoadsEnv\n",
    "from DeepLearning.Environments.CatanEnv import CatanEnv, ChangingRewardEnv\n",
    "from DeepLearning.Environments.SelfPlayEnv import SelfPlayEnv, SelfPlaySetupDotTotalEnv\n",
    "import os\n",
    "from Game.CatanPlayer import PlayerStatsTracker\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from tabulate import tabulate\n",
    "from DeepLearning.Stats import headers\n",
    "import pandas as pd\n",
    "import random\n",
    "from CatanData.GameStateViewer import SaveGameStateImage, DisplayImage\n",
    "import time\n",
    "\n",
    "\n",
    "os.environ[\"UPDATE_MODELS\"] = \"False\"\n",
    "os.environ[\"MODEL_NAME\"] = \"None\"\n",
    "env = ChangingRewardEnv()\n",
    "# modelName = \"FirstSettlement_reward25_5M\"\n",
    "\n",
    "# model = MaskablePPO.load('DeepLearning/Models/Full/Full_vpAction.zip')\n",
    "\n",
    "rewardList = []\n",
    "winner = [0,0,0,0]\n",
    "\n",
    "players = [ AgentRandom2(\"P0\", 0),\n",
    "            AgentRandom2(\"P1\", 1),\n",
    "            AgentRandom2(\"P2\", 2),\n",
    "            AgentRandom2(\"P3\", 3)]\n",
    "\n",
    "for episode in range(1):\n",
    "    done = False\n",
    "    state, info = env.reset()#players=players)\n",
    "\n",
    "    while done != True:\n",
    "        action_masks = get_action_masks(env)\n",
    "        action, _states = model.predict(state, action_masks=action_masks)\n",
    "        state, reward, done, _, info = env.step(action.item())\n",
    "        rewardList.append(reward)\n",
    "\n",
    "    winner[env.game.gameState.winner] += 1\n",
    "    \n",
    "    env.game.gameState.players[0].generatePlayerStats()\n",
    "    env.game.gameState.players[3].generatePlayerStats()\n",
    "\n",
    "    # print(env.game.gameState.players[0].stats)\n",
    "    # DisplayImage(env.game.gameState)\n",
    "    # print(rewardList[-1] - 25)\n",
    "print(rewardList)\n",
    "print(sum(rewardList))\n",
    "\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentName             WinRate    MarginError    numTurns    victoryPoints    numRoadsBuilt    devCardsBought  usedDevCards                         settlementsBuilt    citiesBuilt    devCardVP    largestArmy    longestRoad  resourcesReceived                           totalResourcesReceivedPerTurn    totalResourcesDiscarded    totalResourcesStolen  resourcesFromDevCard                   totalResourcesFromDevCard  resourcesFromBankTrade                 totalResourcesFromBankTrade  finalResourceProduction              finalTradeRates                                                                                      setupResourceProduction                totalSetupResourceProduction  setupTradeRates                        setupResourceDiversity    turnsForFirstSettlement    noSettlementsBuilt    turnsForFirstCity    noCitysBuilt\n",
      "------------------  ---------  -------------  ----------  ---------------  ---------------  ----------------  ---------------------------------  ------------------  -------------  -----------  -------------  -------------  ----------------------------------------  -------------------------------  -------------------------  ----------------------  -----------------------------------  ---------------------------  -----------------------------------  -----------------------------  -----------------------------------  ---------------------------------------------------------------------------------------------------  -----------------------------------  ------------------------------  -----------------------------------  ------------------------  -------------------------  --------------------  -------------------  --------------\n",
      "Player0                  0.33           9.22     73.08            7.12             11.86             4.92     [2.7, 0.37, 0.33, 0.27, 0.0]                  2.51          1.06          1.05          0.31           0.34      [26.49, 30.71, 39.24, 32.53, 34.63]                                 2.239                    28.73                   11.43    [0.64, 0.23, 0.27, 0.13, 0.11]                             1.38   [8.27, 8.0, 7.33, 7.71, 7.42]                               38.73   [5.61, 7.21, 7.11, 6.94, 6.96]       [3.48, 3.38, 3.28, 3.44, 3.32]                                                                       [2.48, 2.74, 3.37, 2.79, 2.85]                                   14  [3.57, 3.49, 3.38, 3.53, 3.41]                        3.26                       42.5                       28              47.2698              37\n",
      "Player0LossesStats      -1             -1        75.1493          5.62687          10.9701           4.86567  [2.552, 0.388, 0.388, 0.284, 0.0]             2.44776       0.656716      1.02985       0.164179       0.149254  [21.343, 27.269, 40.149, 27.388, 31.328]                            1.962                    25.1493                 11.0149  [0.746, 0.313, 0.269, 0.119, 0.119]                        1.566  [8.284, 7.881, 6.761, 7.134, 7.134]                         37.194  [3.851, 5.075, 6.224, 4.761, 5.313]  [3.4925373134328357, 3.388059701492537, 3.2238805970149254, 3.4029850746268657, 3.3134328358208953]  [2.119, 2.537, 3.642, 2.522, 2.716]                              14  [3.552, 3.463, 3.299, 3.463, 3.403]                   3.14925                    50.2308                    28              49.4194              36\n",
      "Player1                  0.28           8.8      72.99            6.2              10.96             4.54     [2.42, 0.3, 0.33, 0.36, 0.0]                  2.29          0.92          1.03          0.23           0.26      [21.06, 28.08, 28.54, 27.83, 26.33]                                 1.806                    22.79                    9.82    [0.62, 0.35, 0.41, 0.32, 0.26]                             1.96   [6.43, 5.77, 5.42, 5.79, 5.39]                              28.8    [4.32, 5.19, 5.23, 5.54, 5.53]       [3.41, 3.44, 3.55, 3.36, 3.39]                                                                       [2.31, 2.36, 2.73, 2.59, 2.54]                                   13  [3.59, 3.67, 3.72, 3.55, 3.56]                        3.08                       50.6538                    48              36.234               53\n",
      "\n",
      "\n",
      "Winnings:  [33, 28, 25, 14]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running Agent simulations\n",
    "\"\"\"\n",
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from Agents.AgentUCT import AgentUCT\n",
    "from Agents.AgentModel import AgentMultiModel, AgentModel\n",
    "from Game.CatanGame import *\n",
    "from CatanSimulator import CreateGame\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from Game.CatanPlayer import PlayerStatsTracker\n",
    "from tabulate import tabulate\n",
    "from DeepLearning.Stats import headers\n",
    "import dill as pickle\n",
    "import pandas as pd\n",
    "from CatanData.GameStateViewer import SaveGameStateImage, DisplayImage\n",
    "import time\n",
    "import math\n",
    "from DeepLearning.GetObservation import getObservationSimplified\n",
    "\n",
    "\n",
    "winner = [0,0,0,0]\n",
    "player0Stats = PlayerStatsTracker()\n",
    "Player0LosingStats = PlayerStatsTracker()\n",
    "player1Stats = PlayerStatsTracker()\n",
    "\n",
    "players = [ AgentModel(\"P0\", 0, model=MaskablePPO.load('DeepLearning/Models/BEST_MODEL_EVER/BEST_MODEL_EVER_178176.zip')),\n",
    "            AgentRandom2(\"P1\", 1),\n",
    "            AgentRandom2(\"P2\", 2),\n",
    "            AgentRandom2(\"P3\", 3)]\n",
    "\n",
    "COLLECT_STATS = True\n",
    "\n",
    "numTurns = 0\n",
    "for episode in range(100):\n",
    "    game = CreateGame(players)\n",
    "    game = pickle.loads(pickle.dumps(game, -1))\n",
    "    while True:\n",
    "        currPlayer = game.gameState.players[game.gameState.currPlayer]\n",
    "\n",
    "        agentAction = currPlayer.DoMove(game)\n",
    "        agentAction.ApplyAction(game.gameState)\n",
    "\n",
    "        # if currPlayer.seatNumber == 0 and agentAction.type == 'EndTurn':\n",
    "        #     numTurns += 1\n",
    "        #     DisplayImage(game.gameState, agentAction.type)\n",
    "        #     time.sleep(1)\n",
    "\n",
    "        if game.gameState.currState == \"OVER\":\n",
    "            break\n",
    "   \n",
    "    winner[game.gameState.winner] += 1\n",
    "    lost = game.gameState.winner != 0\n",
    "\n",
    "    # Stats\n",
    "    if COLLECT_STATS:\n",
    "        game.gameState.players[0].generatePlayerStats()\n",
    "        game.gameState.players[1].generatePlayerStats()\n",
    "\n",
    "        player0Stats += game.gameState.players[0].stats\n",
    "        player1Stats += game.gameState.players[1].stats\n",
    "        if lost:\n",
    "            Player0LosingStats += game.gameState.players[0].stats\n",
    "\n",
    "# Collect stats\n",
    "if COLLECT_STATS:\n",
    "    player0Stats.getAverages()\n",
    "    Player0LosingStats.getAverages()\n",
    "    player1Stats.getAverages()\n",
    "    player0Data = player0Stats.getList()\n",
    "    player0LosingData = Player0LosingStats.getList()\n",
    "    player1Data = player1Stats.getList()\n",
    "\n",
    "    p_hat0 = winner[0] / sum(winner)\n",
    "    p_hat1 = winner[1] / sum(winner)\n",
    "    margin_error0 = round(100*(1.96 * math.sqrt((p_hat0 * (1 - p_hat0)) / sum(winner))), 2)\n",
    "    margin_error1 = round(100*(1.96 * math.sqrt((p_hat1 * (1 - p_hat1)) / sum(winner))), 2)\n",
    "    player0Data.insert(0, margin_error0)\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, margin_error1)\n",
    "    player0Data.insert(0, winner[0]/sum(winner))\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, winner[1]/sum(winner))\n",
    "    player0Data.insert(0, \"Player0\")\n",
    "    player0LosingData.insert(0, \"Player0LossesStats\")\n",
    "    player1Data.insert(0, \"Player1\")\n",
    "\n",
    "    table = tabulate([player0Data, player0LosingData, player1Data], headers=headers, tablefmt='simple')\n",
    "    print(table)\n",
    "\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "\n",
    "# Save to csv\n",
    "# fileName = f'ChangingReward_DiversityProd_wins_500k_vs_3Random.csv'\n",
    "# df = pd.DataFrame([player0Data, player0LosingData, player1Data], columns=headers)\n",
    "# df.to_csv(f'DeepLearning/Data/{fileName}', index=False)\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update models functions\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from DeepLearning.GetObservation import getObservation\n",
    "\n",
    "model=MaskablePPO.load('DeepLearning/Models/Full_vp_100k.zip')\n",
    "print(model.getActionMask)\n",
    "print(model.getObservation)\n",
    "# model.getObservation = getObservation\n",
    "# model.save('DeepLearning/Models/Full_vp_100k.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
