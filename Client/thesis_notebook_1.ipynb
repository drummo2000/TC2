{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldrummond/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.1     |\n",
      "|    ep_rew_mean     | -9.8     |\n",
      "| time/              |          |\n",
      "|    fps             | 424      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.9        |\n",
      "|    ep_rew_mean          | -9.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 371         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017530415 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0.0908      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0394      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.052      |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldrummond/Catan/PyCatron/TC2/Client/env/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:283: UserWarning: Path 'DeepLearning/Thesis/Opponents/Models/VsModel' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.4        |\n",
      "|    ep_rew_mean          | -10         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028357014 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0487     |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 43.5       |\n",
      "|    ep_rew_mean          | -10        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 357        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04018464 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.76      |\n",
      "|    explained_variance   | 0.517      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0772    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0651    |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.9        |\n",
      "|    ep_rew_mean          | -9.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 351         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044805817 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0891     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0698     |\n",
      "|    value_loss           | 0.0572      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48          |\n",
      "|    ep_rew_mean          | -9.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 353         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032506056 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0718     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0506     |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.7        |\n",
      "|    ep_rew_mean          | -9.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040035862 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.088      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0541     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57          |\n",
      "|    ep_rew_mean          | -9.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034585286 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0488     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0451     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 63.5       |\n",
      "|    ep_rew_mean          | -9         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 366        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 100        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03756415 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.61      |\n",
      "|    explained_variance   | 0.437      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0868    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.048     |\n",
      "|    value_loss           | 0.143      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.8        |\n",
      "|    ep_rew_mean          | -9          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 370         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027720258 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.0546      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0598     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0315     |\n",
      "|    value_loss           | 0.303       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.1        |\n",
      "|    ep_rew_mean          | -8.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039327204 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0349     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 72.6       |\n",
      "|    ep_rew_mean          | -8         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 373        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 131        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02317983 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | 0.157      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.045      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.03      |\n",
      "|    value_loss           | 0.442      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 74.1        |\n",
      "|    ep_rew_mean          | -8.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026566196 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.324       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DeepLearning.PPO.MaskablePPO at 0x162064a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from DeepLearning.PPO import MaskablePPO\n",
    "from DeepLearning.Thesis.Environments.VsModel import VsModel\n",
    "from DeepLearning.GetActionMask import getActionMask\n",
    "from DeepLearning.Thesis.Observations.get_observation import getObservation, lowerBound, upperBound\n",
    "import os\n",
    "\n",
    "env = VsModel()\n",
    "actionMask = getActionMask\n",
    "observation = getObservation\n",
    "\n",
    "netArchDict = dict(pi=[128, 128, 128], vf=[128, 128, 128])\n",
    "gamma = 0.99\n",
    "n_steps = 4096\n",
    "\n",
    "saveName = \"VsModel\"\n",
    "savePath = f\"DeepLearning/Thesis/Opponents/Models/{saveName}\"\n",
    "\n",
    "model = MaskablePPO(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=netArchDict), gamma=gamma, n_steps=n_steps, getActionMask=actionMask, getObservation=observation, savePath=savePath) #, tensorboard_log=\"./tensorboard_logs_thesis/\")\n",
    "model.savePath = savePath\n",
    "model.learn(total_timesteps=4_000_000) #, tb_log_name=saveName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentName             WinRate    MarginError    numTurns    victoryPoints    numRoadsBuilt    devCardsBought  usedDevCards                         settlementsBuilt    citiesBuilt    devCardVP    largestArmy    longestRoad  resourcesReceived                           totalResourcesReceivedPerTurn    totalResourcesDiscarded    totalResourcesStolen  resourcesFromDevCard               totalResourcesFromDevCard  resourcesFromBankTrade               finalResourceProduction              finalTradeRates                                                                                     setupResourceProduction                totalSetupResourceProduction  setupTradeRates                        setupResourceDiversity    turnsForFirstSettlement    noSettlementsBuilt    turnsForFirstCity    noCitysBuilt    numRoadsFor1stSettlement    totalResourcesFromBankTrade    goodSettlementBankTrades    badSettlementBankTrades    goodCityBankTrades    badCityBankTrades    goodRoadBankTrades    badRoadBankTrades    goodDevCardBankTrades    badDevCardBankTrades    neutralBankTrades    acceptedTrades    rejectedTrades    goodSettlementAcceptedTrades    badSettlementAcceptedTrades    goodCityAcceptedTrades    badCityAcceptedTrades    goodRoadAcceptedTrades    badRoadAcceptedTrades    goodDevCardAcceptedTrades    badDevCardAcceptedTrades    neutralAcceptedTrades    totalPlayerTrades    acceptedPlayerTrades    goodSettlementPlayerTrades    badSettlementPlayerTrades    goodCityPlayerTrades    badCityPlayerTrades    goodRoadPlayerTrades    badRoadPlayerTrades    goodDevCardPlayerTrades    badDevCardPlayerTrades    neutralPlayerTrades\n",
      "------------------  ---------  -------------  ----------  ---------------  ---------------  ----------------  ---------------------------------  ------------------  -------------  -----------  -------------  -------------  ----------------------------------------  -------------------------------  -------------------------  ----------------------  -------------------------------  ---------------------------  -----------------------------------  -----------------------------------  --------------------------------------------------------------------------------------------------  -----------------------------------  ------------------------------  -----------------------------------  ------------------------  -------------------------  --------------------  -------------------  --------------  --------------------------  -----------------------------  --------------------------  -------------------------  --------------------  -------------------  --------------------  -------------------  -----------------------  ----------------------  -------------------  ----------------  ----------------  ------------------------------  -----------------------------  ------------------------  -----------------------  ------------------------  -----------------------  ---------------------------  --------------------------  -----------------------  -------------------  ----------------------  ----------------------------  ---------------------------  ----------------------  ---------------------  ----------------------  ---------------------  -------------------------  ------------------------  ---------------------\n",
      "Player0                0.4318           1.37     29.4484          7.6776           9.967             5.881    [3.111, 0.429, 0.431, 0.435, 0.0]             1.7324        1.3328       1.2088         0.3628         0.304     [15.674, 16.018, 20.09, 20.814, 21.467]                             3.194                    14.9972                 5.718    [0.434, 1.652, 0.0, 0.0, 0.0]                          2.086  [2.824, 3.32, 2.261, 2.656, 2.156]   [6.893, 7.454, 8.967, 9.705, 9.425]  [3.5158, 3.525, 3.5366, 3.5438, 3.5286]                                                             [3.355, 3.409, 4.508, 4.489, 4.61]                           20.371  [3.991, 3.991, 3.991, 3.991, 3.991]                   3.8558                    10.9591               0.2188                9.66004        0.333                        3.10834                         13.217                    0.5246                   0.008                   0.2036              0.008                   2.6222              0.1496                    1.7762                 0.2492                7.8094                  0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "Player0LossesStats    -1               -1        30.0187          5.73918          9.38684           4.53045  [2.428, 0.339, 0.359, 0.315, 0.0]             1.27385       0.842309     0.874692       0.169307       0.143259  [14.794, 14.099, 19.139, 17.422, 20.422]                            2.861                    14.2893                 6.30271  [0.36, 1.214, 0.0, 0.0, 0.0]                           1.574  [2.689, 2.719, 2.043, 2.9, 2.144]    [5.724, 5.787, 7.573, 7.212, 7.975]  [3.6187961985216472, 3.614572333685322, 3.6230200633579726, 3.6254839845124955, 3.643435410066878]  [3.385, 3.177, 4.584, 4.014, 4.725]                          19.885  [3.986, 3.986, 3.986, 3.988, 3.988]                   3.67441                    9.96459              0.342133              7.50046        0.508624                     2.76626                         12.495                    0.476945                 0.00915171              0.132348            0.0063358               2.43471             0.133404                  1.56811                0.268215              7.59099                 0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "Player1                0.3762           1.34     29.2716          7.2156           9.4864            5.6292   [2.92, 0.4, 0.416, 0.431, 0.0]                1.4084        1.1982       1.1378         0.3188         0.3804    [14.885, 15.806, 18.914, 20.26, 18.946]                             3.034                    10.0898                 6.323    [0.631, 0.834, 0.0, 0.741, 0.0]                        2.206  [2.549, 3.743, 1.899, 3.226, 1.872]  [6.537, 7.194, 8.213, 9.135, 8.264]  [3.6908, 3.704, 3.6988, 3.7062, 3.6832]                                                             [3.438, 3.378, 4.459, 4.496, 4.344]                          20.115  [3.996, 3.996, 3.996, 3.997, 3.997]                   3.7594                    10.4772               0.3092                8.89127        0.3794                       2.88578                         13.289                    0.3706                   0.0156                  0.2046              0.0112                  2.1602              0.2178                    1.6428                 0.43                  8.2332                  0                 0                               0                              0                         0                        0                         0                        0                            0                           0                        0                    0                       0                             0                            0                       0                      0                       0                      0                          0                         0                      0\n",
      "\n",
      "Num turns: 0\n",
      "\n",
      "\n",
      "Winnings:  [2159, 1881, 954, 6]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running Agent simulations\n",
    "\"\"\"\n",
    "from Agents.AgentRandom2 import AgentRandom2\n",
    "from Agents.AgentMCTS import AgentMCTS\n",
    "from Agents.AgentUCT import AgentUCT\n",
    "from Agents.AgentModel import AgentMultiModel, AgentModel\n",
    "from Game.CatanGame import *\n",
    "from CatanSimulator import CreateGame\n",
    "from DeepLearning.PPO import MaskablePPO\n",
    "from Game.CatanPlayer import PlayerStatsTracker\n",
    "from tabulate import tabulate\n",
    "from DeepLearning.Stats import headers\n",
    "import dill as pickle\n",
    "from CatanData.GameStateViewer import SaveGameStateImage, DisplayImage\n",
    "import math\n",
    "import time\n",
    "\n",
    "winner = [0,0,0,0]\n",
    "player0Stats = PlayerStatsTracker()\n",
    "Player0LosingStats = PlayerStatsTracker()\n",
    "player1Stats = PlayerStatsTracker()\n",
    "\n",
    "testModel = MaskablePPO.load(\"DeepLearning/Thesis/Opponents/Models/Uniform/model_14667776.zip\")\n",
    "testModel2 = MaskablePPO.load(\"DeepLearning/Thesis/Opponents/Models/Distribution/model_14966784.zip\")\n",
    "testModel3 = MaskablePPO.load(\"DeepLearning/Thesis/Rewards/Models/Reward_win/Reward_win_10M.zip\")\n",
    "# # testModel4 = MaskablePPO.load(\"DeepLearning/Thesis/Hyperparameters/Models/NetworkArch_512_512/Final.zip\")\n",
    "\n",
    "players = [ AgentModel(\"P0\", 0, recordStats=True, playerTrading=False, model=testModel),\n",
    "            # AgentUCT(\"P1\", 0, recordStats=True, simulationCount=500),\n",
    "            AgentModel(\"P1\", 1, recordStats=True, playerTrading=False, model=testModel2),\n",
    "            AgentModel(\"P2\", 2, recordStats=True, playerTrading=False, model=testModel3),\n",
    "            # AgentModel(\"P3\", 3, recordStats=True, playerTrading=False, model=testModel2),\n",
    "            # AgentRandom2(\"P1\", 1, recordStats=True, playerTrading=False),\n",
    "            # AgentRandom2(\"P2\", 2, recordStats=True, playerTrading=False),\n",
    "            AgentRandom2(\"P3\", 3, recordStats=True, playerTrading=False),\n",
    "            ]\n",
    "\n",
    "\n",
    "COLLECT_STATS = True\n",
    "for episode in range(5000):\n",
    "    game = CreateGame(players)\n",
    "    game = pickle.loads(pickle.dumps(game, -1))\n",
    "    numTurns = 0\n",
    "    while True:\n",
    "        currPlayer = game.gameState.players[game.gameState.currPlayer]\n",
    "\n",
    "        agentAction = currPlayer.DoMove(game)\n",
    "        agentAction.ApplyAction(game.gameState)\n",
    "\n",
    "        # if currPlayer.seatNumber == 0 and agentAction.type == 'EndTurn':\n",
    "        #     DisplayImage(game.gameState, agentAction)\n",
    "        #     time.sleep(0.25)\n",
    "        #     numTurns += 1\n",
    "\n",
    "        if game.gameState.currState == \"OVER\":\n",
    "            # DisplayImage(game.gameState, agentAction)\n",
    "            break\n",
    "    \n",
    "    # print(\"Winner: \", game.gameState.winner)\n",
    "    winner[game.gameState.winner] += 1\n",
    "    lost = game.gameState.winner != 0\n",
    "\n",
    "    # print(winner)\n",
    "\n",
    "    # Stats\n",
    "    if COLLECT_STATS:\n",
    "        game.gameState.players[0].generatePlayerStats()\n",
    "        game.gameState.players[1].generatePlayerStats()\n",
    "\n",
    "        player0Stats += game.gameState.players[0].stats\n",
    "        player1Stats += game.gameState.players[1].stats\n",
    "        if lost:\n",
    "            Player0LosingStats += game.gameState.players[0].stats\n",
    "\n",
    "# Collect stats\n",
    "if COLLECT_STATS:\n",
    "    player0Stats.getAverages()\n",
    "    Player0LosingStats.getAverages()\n",
    "    player1Stats.getAverages()\n",
    "    player0Data = player0Stats.getList()\n",
    "    player0LosingData = Player0LosingStats.getList()\n",
    "    player1Data = player1Stats.getList()\n",
    "\n",
    "    p_hat0 = winner[0] / sum(winner)\n",
    "    p_hat1 = winner[1] / sum(winner)\n",
    "    margin_error0 = round(100*(1.96 * math.sqrt((p_hat0 * (1 - p_hat0)) / sum(winner))), 2)\n",
    "    margin_error1 = round(100*(1.96 * math.sqrt((p_hat1 * (1 - p_hat1)) / sum(winner))), 2)\n",
    "    player0Data.insert(0, margin_error0)\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, margin_error1)\n",
    "    player0Data.insert(0, winner[0]/sum(winner))\n",
    "    player0LosingData.insert(0, -1)\n",
    "    player1Data.insert(0, winner[1]/sum(winner))\n",
    "    player0Data.insert(0, \"Player0\")\n",
    "    player0LosingData.insert(0, \"Player0LossesStats\")\n",
    "    player1Data.insert(0, \"Player1\")\n",
    "\n",
    "    table = tabulate([player0Data, player0LosingData, player1Data], headers=headers, tablefmt='simple')\n",
    "    print(table)\n",
    "\n",
    "print(f\"\\nNum turns: {numTurns}\")\n",
    "\n",
    "print(\"\\n\\nWinnings: \", winner)\n",
    "\n",
    "\n",
    "# Brick, ore, wool, wheat, wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save to csv\n",
    "fileName = f'SP_Uniform_v_Distribution.csv'\n",
    "df = pd.DataFrame([player0Data, player0LosingData, player1Data], columns=headers)\n",
    "df.to_csv(f'DeepLearning/Thesis/Opponents/Data/{fileName}', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
